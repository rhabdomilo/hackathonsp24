# -*- coding: utf-8 -*-
"""hackpus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jA0rqi9kkmB0qoD0zzK7CrXExMtJaERq
"""

!pip install langchain
!pip install python-dotenv
!pip install openai
!pip install nltk
!pip install langchain_openai
!pip install faiss-cpu

from langchain.document_loaders.csv_loader import CSVLoader
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain

import openai
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import csv
import re
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import os

# Set your OpenAI API key directly
openai_api_key = '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'
openai.api_key = openai_api_key

# Initialize OpenAIEmbeddings with the API key
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)

def vector_search(query):
    similar_response = vectorstore.similarity_search(query, k=3)

    contents_array = [doc.page_content for doc in similar_response]

    return contents_array

model = ChatOpenAI(openai_api_key=openai_api_key, temperature=0, model="gpt-3.5-turbo")

# Your template
template = """
{vector_search_results}

data:
{input_message}

"""

prompt = PromptTemplate(
    input_variables=["input message", "vector_search_results"],
    template=template
)

chain = LLMChain(llm=model, prompt=prompt)

def get_response(input_message):
    input_data = {
        'input_message': input_message,
        'vector_search_results': """
    You're an AI researcher building a vector similarity search training set.
    I am going to give you knowledge-based data, and from it, you will output 10 queries, answer pairs separated by a comma in the following format.

    What are some examples of courses that satisfy the Cultures requirement? , Some examples of courses that satisfy the Cultures requirement include COMM 451, COMM 452, COMM 453, COMM 454, COMM 455, COMM 495, and COMM 496.

    Please remember your answer format is a question answer pair separated by a comma.
    Provide 10 query answer pairs at a time. Be specific yet, informal. Name in your questions and answers
    things related to the data, include background content that contextualizes
    the query. Include important information from the data in both your query
    and answers. Within the answers do not use any falsified or extrapolated
    answers. Try to sound as human as possible, and generate as many table
    queries as necessary to properly cover the information given to you.
    Write complete queries and answers, and always reference information in the input.
    Always generate a query table that sounds human and friendly. As an advisor should.

    do not provide any extra content. Only the set of pairs."""
    }
    response = chain.run(input_data)
    return response

def create_chunks_from_txt(file_path, chunk_size=2000):
    """
    Reads a cleaned text file and creates a list of strings,
    each up to 2000 characters long.

    :param file_path: Path to the input text file.
    :param chunk_size: The maximum size of each chunk (default 2000 characters).
    :return: A list of string chunks from the file.
    """
    # Initialize an empty list to hold the chunks
    chunks = []

    # Read the entire content of the file
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()

    # Create chunks of 2000 characters
    for i in range(0, len(content), chunk_size):
        chunks.append(content[i:i+chunk_size])

    return chunks

csv_file_path = 'output.csv'
input_message = create_chunks_from_txt("2nd.txt")


# Open the CSV file in append mode
with open(csv_file_path, 'a', newline='', encoding='utf-8') as csvfile:
    csvwriter = csv.writer(csvfile)

    # Loop through each input message
    for i in input_message:
        # Get the response for the current input message
        response = get_response(i)

        # Write the input message and response as a row in the CSV file
        csvwriter.writerow([i, response])